{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6061331b-1446-4929-8307-f37284b940b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from Dynamic_only import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.interpolate import CubicSpline, PchipInterpolator \n",
    "import time\n",
    "import ast\n",
    "import os\n",
    "import shutil\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2428fc0-dffd-4922-a1ef-59a0c1903999",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_intervals = pd.read_csv(\"../key_intervals.csv\")\n",
    "pattern_dates = pd.read_csv(\"../patterns_dates.csv\", parse_dates=[0,1,2,3,4,5], date_format=\"%d/%m/%Y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e839fabd-0460-4ce9-b7d0-3d529732b472",
   "metadata": {},
   "outputs": [],
   "source": [
    "key_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2977b7d0-d1d5-49d5-bfa1-390bc12d7a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replication IDs mapped to their time interval\n",
    "replication_ids = {'0500': 16686964, '0515': 16686990, '0530': 16686994, '0545': 16687067, '0600': 16687000, '0615': 16687004, '0630': 16687068,\n",
    " '0645': 16687010, '0700': 16687014, '0715': 16687018, '0730': 16687026, '0745': 16687028, '0800': 16687030, '0815': 16687048, '0830': 16687050,\n",
    " '0845': 16687053, '0900': 16687055, '0915': 16687057, '0930': 16687059, '0945': 16687061}\n",
    "\n",
    "# time intervals mapped to the corresponding time interval\n",
    "time_intervals = {index: key for index, key in enumerate(replication_ids.keys())}\n",
    "time_intervals.update({-1:'0445'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e07766-153e-4a12-ba06-8019fde47ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mono_cubic_interp(hook_pts, data, length):\n",
    "    \"\"\"\n",
    "    Returns interpolated list of values \n",
    "    \n",
    "    param hook_pts: List containing the hook points of a dataset to be interpolated\n",
    "    param data: List containing the values at the given hook points\n",
    "    param length: Length of required dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    function = PchipInterpolator(hook_pts, data)\n",
    "    x_new = np.array(range(length))\n",
    "    interpolated_data_mono = function(x_new)\n",
    "    return interpolated_data_mono\n",
    "\n",
    "\n",
    "def output_od(vector_od):\n",
    "    lookup = pd.read_csv(\"OD lookup.csv\")\n",
    "    lookup['count'] = vector_od\n",
    "    lookup = lookup.pivot(index='id', columns='Destination')[['count']]\n",
    "    return lookup['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170840a8-dcf4-4b51-ada4-5ba55505becd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interepolate_ODs():\n",
    "    hookpts = pattern_key_intervals\n",
    "    filenames = os.listdir(\"../Simulation ODs/\")[1:-1]\n",
    "    od_series = vectorize_od(pd.read_csv(f\"../Simulation ODs/{filenames[0]}\", index_col = \"id\"))\n",
    "    for i in range(1, len(filenames)):\n",
    "        new = vectorize_od(pd.read_csv(f\"../Simulation ODs/{filenames[i]}\", index_col = \"id\"))\n",
    "        new = new.rename({0:i}, axis = 1)\n",
    "        od_series = pd.concat([od_series, new], axis = 1)\n",
    "    np_od = od_series.to_numpy()\n",
    "    total_od = od_series.sum(axis = 1)\n",
    "    non_zero_indices = [i for i in range(len(total_od)) if total_od[i] != 0 ]\n",
    "    non_zero = [total_od[i] for i in non_zero_indices]\n",
    "    \n",
    "    for index in non_zero_indices:    \n",
    "        data = np_od[index]\n",
    "        inter_data = [data[i] for i in range(len(data)) if i in hookpts]\n",
    "        new_data = mono_cubic_interp(hookpts, inter_data, 20)\n",
    "        np_od[index] = new_data\n",
    "\n",
    "    for file_index in range(20):\n",
    "        output = output_od(np_od[:, file_index]).applymap(lambda x: 0 if x < 0 or np.isnan(x) else round(x))\n",
    "        output.to_csv(\"../Simulation ODs/\" + filenames[file_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c05835f1-e5ca-4fec-9703-1e571f01a998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declare constants\n",
    "MAX_ASSIGNMENT_ITERATIONS = 5\n",
    "GRADIENT_DESCENT_ITERATIONS = 8\n",
    "OBJECTS_FILE = \"sections_list.txt\"\n",
    "# DATE = str(pattern_dates[f'pattern_{pattern_id}'][0].date())\n",
    "loss_evaluation = [] # list of loss function values at each iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879e1868-4eb1-4f94-85e3-4f96840be34b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for pattern_id in range(9,10):\n",
    "    pattern_key_intervals = ast.literal_eval(key_intervals.iloc[pattern_id - 4, 1])\n",
    "    if not os.path.exists(f\"../Output ODs/{pattern_id}/\"):\n",
    "        os.mkdir(f\"../Output ODs/{pattern_id}/\")\n",
    "    for date_id in range(5,6):\n",
    "        DATE = pattern_dates[f'pattern_{pattern_id}'][date_id]\n",
    "        if str(DATE) != \"NaT\":\n",
    "            DATE = str(DATE.date())\n",
    "            if not os.path.exists(f\"../Output ODs/{pattern_id}/{DATE}/\"):\n",
    "                os.mkdir(f\"../Output ODs/{pattern_id}/{DATE}/\")\n",
    "            for outer_iterations in tqdm(range(MAX_ASSIGNMENT_ITERATIONS), leave = False):\n",
    "                for interval in pattern_key_intervals:\n",
    "                    time_interval = time_intervals[interval] # 24-hour time interval\n",
    "                    run_sim(replication_ids[time_interval], time_interval) # Run simulation (should output a file \"assignment_time_interval.txt\" at the current location\n",
    "                    assignment_filepath = f\"assignment/assignment.txt\"\n",
    "                    aimsun_assignment = read_aimsun_assignment(assignment_filepath) # Generate assignment dataframe \n",
    "                    dynamic_matrices = create_dynamic_assignments(aimsun_assignment, OBJECTS_FILE, time_intervals, interval) # create dynamic assignment matrices\n",
    "                    for inner_iterations in tqdm(range(GRADIENT_DESCENT_ITERATIONS), leave = False):\n",
    "                        # loss_evaluation.append(objective_function(dynamic_matrices, time_intervals, interval, pattern_id, DATE))\n",
    "                        dynamic_ods = get_dynamic_od(time_intervals, interval)\n",
    "                        interval_gradients = gradient_interval(dynamic_matrices, time_intervals, interval, pattern_id, DATE)\n",
    "                        step_length = step_len_interval(dynamic_ods, dynamic_matrices, interval_gradients, time_intervals, interval, pattern_id, DATE)\n",
    "                        dynamic_ods[1] = dynamic_ods[1]*(1 - interval_gradients[1]*step_length[1][0])\n",
    "                        update_ods(dynamic_ods[1], time_interval)\n",
    "                interepolate_ODs()\n",
    "            # Move adjusted ODs to the output folder\n",
    "            for filenames in os.listdir(\"../Simulation ODs/\"):\n",
    "                os.rename(f\"../Simulation ODs/{filenames}\", f\"../Output ODs/{pattern_id}/{DATE}/{filenames}\")\n",
    "\n",
    "            # Copy prior ODs to the simulation ODs folder\n",
    "            for filenames in os.listdir(f\"../Pattern ODs/{pattern_id}/\"):\n",
    "                shutil.copy(f\"../Pattern ODs/{pattern_id}/{filenames}\", \"../Simulation ODs/\")\n",
    "            print(f\"{DATE} completed for Pattern {pattern_id}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e6df86",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE = \"2021-06-02\"\n",
    "pattern_id = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201d6949",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for pattern_id in range(5,10):\n",
    "    for date_id in tqdm(range(10), leave = False):\n",
    "        DATE = pattern_dates[f'pattern_{pattern_id}'][date_id]\n",
    "        if str(DATE) != \"NaT\":\n",
    "            DATE = str(DATE.date())\n",
    "            if not os.path.exists(f\"../Estimated flows/{pattern_id}/{DATE}/\"):\n",
    "                os.mkdir(f\"../Estimated flows/{pattern_id}/{DATE}/\")\n",
    "            for filename in os.listdir(f\"../Output ODs/{pattern_id}/{DATE}/\"):\n",
    "                shutil.copy(f\"../Output ODs/{pattern_id}/{DATE}/{filename}\", \"../Simulation ODs/\")\n",
    "            for interval in tqdm(range(20), leave = False):\n",
    "                time_interval = time_intervals[interval]\n",
    "                run_sim(replication_ids[time_interval], time_interval) # Run simulation (should output a file \"assignment_time_interval.txt\" at the current location\n",
    "                assignment_filepath = f\"assignment/assignment.txt\"\n",
    "                aimsun_assignment = read_aimsun_assignment(assignment_filepath) # Generate assignment dataframe \n",
    "                dynamic_matrices = create_dynamic_assignments(aimsun_assignment, OBJECTS_FILE, time_intervals, interval)\n",
    "                flows = estimate_dynamic_flow(dynamic_matrices, time_intervals, interval, 1)\n",
    "                flows.to_csv(f\"../Estimated flows/{pattern_id}/{DATE}/{time_intervals[interval]}.csv\", index = False)\n",
    "            print(f\"{DATE} for {pattern_id} completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a2f499",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
