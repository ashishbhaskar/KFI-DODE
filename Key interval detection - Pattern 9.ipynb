{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7302cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import scipy.interpolate\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0db3d521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_od(input_od):\n",
    "    \"\"\"\n",
    "    Function used to convert an OD matrix to its vector form\n",
    "\n",
    "    params: \n",
    "        input_od (pd.DataFrame)\n",
    "    returns: \n",
    "        od (as a vector)(np.array)\n",
    "    \"\"\"\n",
    "    od = input_od.copy()\n",
    "    od.reset_index(inplace=True)\n",
    "    od = od.melt(id_vars=['id'])\n",
    "    od.drop(od[(od['id'] == 'Total') | (od['variable'] == 'Total')].index, inplace=True)\n",
    "    od['OD'] = (od['id'].astype(str) + od['variable'].astype(str)).astype(\"int64\")\n",
    "    columns = od.columns.to_list()\n",
    "    od = od[columns[-1:] + columns[2:3]]\n",
    "    od = od.sort_values(\"OD\")\n",
    "    od.drop(\"OD\", axis=1, inplace=True)\n",
    "    od.columns = range(od.columns.size)\n",
    "    od.reset_index(inplace=True)\n",
    "    od = od.drop(\"index\", axis=1)\n",
    "    return od"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14a09c1d-fbba-4d63-a999-42f31631e12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_consecutive_numbers(lst):\n",
    "    for i in range(len(lst) - 1):\n",
    "        if (lst[i] + 1 == lst[i+1]):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def filter_consecutive_lists(lists):\n",
    "    result = []\n",
    "    for sublist in lists:\n",
    "        if not has_consecutive_numbers(sublist):\n",
    "            result.append(list(sublist))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d701b250-0f3e-43bb-a386-170334a3e896",
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = list(itertools.combinations(range(20), 4))\n",
    "combinations = filter_consecutive_lists(combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3866e0e-006e-4e84-b7ba-139f3b21e91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in range(len(combinations)):\n",
    "    if 0 not in combinations[index]:\n",
    "        combinations[index].insert(0,0)\n",
    "    if 19 not in combinations[index]:\n",
    "        combinations[index].append(19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30f67721",
   "metadata": {},
   "outputs": [],
   "source": [
    "combinations = filter_consecutive_lists(combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a4051d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1548"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combinations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588caa45-f911-45bf-b226-a90abfa1e44f",
   "metadata": {},
   "source": [
    "## Generate Total demand vector (D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be072698-14ae-4ace-a153-7062608676ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"Experiment pattern ODs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "508ce3db-c796-4979-a1d3-ba916a6fb37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = os.listdir(\"4/\")\n",
    "filepath = os.path.join(os.getcwd(), \"9\", filenames[1])\n",
    "od_series = vectorize_od(pd.read_csv(filepath, index_col = \"id\"))\n",
    "for i in range(2, len(filenames)-1):\n",
    "    filepath = os.path.join(os.getcwd(), \"9\", filenames[i])\n",
    "    new = vectorize_od(pd.read_csv(filepath, index_col = \"id\"))\n",
    "    new = new.rename({0:i}, axis = 1)\n",
    "    od_series = pd.concat([od_series, new], axis = 1)\n",
    "    \n",
    "total_od = od_series.sum(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b858a594-e66e-4ad9-aaf6-f87d2fe92ab2",
   "metadata": {},
   "source": [
    "## Generate incidence vector (I)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46a31048-864e-4bcd-ae6d-66fa3c7e7dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate(hook_pts, data, length):\n",
    "    \"\"\"\n",
    "    Returns interpolated list of values \n",
    "    \n",
    "    param hook_pts: List containing the hook points of a dataset to be interpolated\n",
    "    param data: List containing the values at the given hook points\n",
    "    param length: Length of required dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    function = scipy.interpolate.PchipInterpolator(hook_pts, data)\n",
    "    x_new = np.array(range(length))\n",
    "    interpolated_data_cubspl = function(x_new)\n",
    "    return interpolated_data_cubspl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "103bdfdf-85a6-4e1f-b270-f24b9f66459b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2784fa360c3e45e1943ea4fd510efd37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80656 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "od_key_intervals = {i: [] for i in range(len(od_series))}\n",
    "for od_index in tqdm(range(len(od_series))):\n",
    "    time_series = od_series.iloc[od_index, :]\n",
    "    errors = []\n",
    "    if total_od[od_index] != 0:\n",
    "        for combination in combinations:\n",
    "            data_points = list(od_series.iloc[od_index, list(combination)])\n",
    "            interpolated_series = interpolate(list(combination), data_points, 20)\n",
    "            errors.append(mean_squared_error(time_series, interpolated_series))\n",
    "        od_key_intervals[od_index] = combinations[errors.index(min(errors))]\n",
    "    else:\n",
    "        continue    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43c4265-efba-43d1-90ce-a15ed02b9c30",
   "metadata": {},
   "source": [
    "## Generate Weight vector (W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bec80ec3-8520-42eb-aa5a-e25464353d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = {interval: 0 for interval in range(20)}\n",
    "for od in range(len(od_series)):\n",
    "    for interval in range(20):\n",
    "        if interval in od_key_intervals[od]:\n",
    "            W[interval]+= total_od[od]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43b4f3d-c84a-4154-ae39-2c6d0c908673",
   "metadata": {},
   "source": [
    "## Get final key intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe095a6f-aa28-4591-9813-ffb04b99db4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "threshold = sorted(W.values(), reverse = True)[4]\n",
    "min_threshold = sorted(W.values(), reverse = True)[9]\n",
    "key_intervals = []\n",
    "start = 0\n",
    "sum = 0\n",
    "interval = 0\n",
    "while interval < 20:\n",
    "    if W[interval] >= threshold:\n",
    "        key_intervals.append(interval)\n",
    "        start = interval\n",
    "        sum = 0\n",
    "        interval = interval + 1\n",
    "    elif W[interval] < min_threshold:\n",
    "        interval += 1\n",
    "        continue\n",
    "    else:\n",
    "        sum = sum+W[interval]\n",
    "        start = interval\n",
    "        while W[interval+1] > min_threshold and W[interval+1]<= threshold:\n",
    "            interval = interval + 1\n",
    "            sum = sum+W[interval]\n",
    "        if sum >= threshold:\n",
    "            middle = (start+interval)//2\n",
    "            key_intervals.append(middle)\n",
    "            interval = middle\n",
    "            sum = 0\n",
    "            interval = interval + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dd71e1-a3d6-4752-8710-935a610a01d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(list(W.values())).to_csv(\"Pattern 9 weight factor.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
